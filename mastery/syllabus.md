# üîµ LLM Mastery ‚Äì Curso Avanzado de Large Language Models

**Duraci√≥n total:** ~120 minutos  
**Prerequisito:** Haber completado el curso *LLM Foundations*  

Curso previo: [LLM Foundations](../foundations/syllabus.md)  

> ‚ö†Ô∏è Nota: En desarrollo

---

## üß© M√≥dulo 1 ‚Äì Cuantizaci√≥n y Optimizaci√≥n de Inferencia
- ¬øQu√© es cuantizaci√≥n?  
- T√©cnicas:  
  - Post-training quantization (PTQ)  
  - Quantization-aware training (QAT)  
  - GPTQ, AWQ, SmoothQuant  
- Tradeoffs: velocidad ‚ö°, memoria üíæ, precisi√≥n üéØ  
- Herramientas pr√°cticas:  
  - `bitsandbytes`, AutoGPTQ, `llm.int8()` (Hugging Face)  
  - GGUF / GGML (CPU inference)  
- **Demo:** Cuantizar un modelo *LLaMA-2-7B* y comparar memoria/velocidad  

---

## üõ†Ô∏è M√≥dulo 2  ‚Äì Optimizaci√≥n de Entrenamiento y Fine-tuning
- QLoRA (LoRA + quantization en training)  
- AdaLoRA y IA3  
- Mixture of Adapters  
- Entrenamiento distribuido: FSDP, DeepSpeed, Megatron-LM  
- T√©cnicas de *gradient checkpointing* y ZeRO optimizer  
- **Demo:** Fine-tuning con QLoRA en un subset reducido de *Alpaca*  

---

## üöÄ M√≥dulo 3  ‚Äì Despliegue de LLMs en Producci√≥n
- Desaf√≠os reales:  
  - Latencia (batching, caching)  
  - Costos (GPU sharing, quantized inference)  
  - Escalabilidad (multi-GPU, clusters)  
- Herramientas:  
  - **vLLM** (fast inference con paged attention)  
  - **TGI** (Text Generation Inference ‚Äì Hugging Face)  
  - **Ray Serve** para escalamiento  
- **Demo:** Deploy de un modelo cuantizado en vLLM y comparaci√≥n con *transformers* est√°ndar  

---

## üß† M√≥dulo 4  ‚Äì T√©cnicas Avanzadas y Casos de Uso
- **Razonamiento Avanzado:**  
  - Chain-of-Thought optimizado (CoT prompting)  
  - Self-Consistency y Tree-of-Thoughts üå≥  
- **Agentes basados en LLMs:**  
  - LangChain + herramientas externas (API calls, ejecuci√≥n de c√≥digo)  
  - HuggingGPT: coordinaci√≥n entre modelos especializados  
- **RAG Avanzado:**  
  - Indexado h√≠brido (denso + BM25)  
  - Multi-query retrievers  
  - Evaluaci√≥n en RAG: *recall@k*, *MRR*  
- **Demo:** Construir un *LLM Agent* que use RAG + ejecuci√≥n de c√≥digo  

---

## üîÆ M√≥dulo 5  ‚Äì Tendencias, Retos y Futuro
- Modelos h√≠bridos: LLMs + MoE (Mixture of Experts)  
- Modelos ligeros para *Edge AI*: TinyLLaMA, Mistral  
- Avances en multimodalidad: Gemini, LLaVA-Next  
- Riesgos: *model collapse* por entrenamiento recursivo  
- Transparencia en cuantizaci√≥n y sesgos ‚öñÔ∏è  

---

## ‚úÖ Objetivos del curso
- Comprender y aplicar t√©cnicas avanzadas de **optimizaci√≥n e inferencia**.  
- Dominar m√©todos de **fine-tuning eficiente** (PEFT, QLoRA, etc.).  
- Saber c√≥mo **desplegar LLMs en producci√≥n** de forma escalable y rentable.  
- Explorar casos de uso avanzados: **RAG, agentes, razonamiento complejo**.  
- Conocer las **tendencias futuras** y los retos en investigaci√≥n y producci√≥n.  
